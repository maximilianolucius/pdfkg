"""Usage tracking utilities for LLM calls."""

from __future__ import annotations

import json
import os
import threading
from collections import Counter, defaultdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Iterable, Optional, Tuple

_CALL_COUNTS: Counter[Tuple[str, str, str]] = Counter()
_TOKEN_TOTALS: Dict[Tuple[str, str, str], Dict[str, int]] = defaultdict(
    lambda: {"tokens_in": 0, "tokens_out": 0, "total_tokens": 0}
)

_LOG_LOCK = threading.Lock()
_LOG_DIR = Path(os.getenv("LLM_LOG_DIR", "data/logs"))
_LOG_DIR.mkdir(parents=True, exist_ok=True)
_LOG_FILE_PATH = _LOG_DIR / "llm_calls.log"


def _write_log_entry(entry: Dict[str, object]) -> None:
    """Persist a single log entry to disk as JSON line."""
    with _LOG_LOCK:
        with _LOG_FILE_PATH.open("a", encoding="utf-8") as log_file:
            log_file.write(json.dumps(entry, ensure_ascii=True) + "\n")


def record_call(
    provider: str,
    phase: str,
    label: str,
    *,
    tokens_in: Optional[int] = None,
    tokens_out: Optional[int] = None,
    total_tokens: Optional[int] = None,
    metadata: Optional[Dict[str, object]] = None,
) -> None:
    """
    Record a single LLM call and append it to the usage log.

    Args:
        provider: LLM provider identifier (e.g., "gemini", "mistral").
        phase: High-level pipeline phase (e.g., "extraction", "qa").
        label: Fine-grained identifier (e.g., "DigitalNameplate.serial").
        tokens_in: Prompt tokens consumed by the request.
        tokens_out: Completion tokens generated by the response.
        total_tokens: Combined tokens if reported by the provider.
        metadata: Additional context (model, latency, etc.).
    """
    key = (provider, phase, label)
    _CALL_COUNTS[key] += 1

    totals = _TOKEN_TOTALS[key]
    if tokens_in is not None:
        totals["tokens_in"] += int(tokens_in)
    if tokens_out is not None:
        totals["tokens_out"] += int(tokens_out)
    if total_tokens is not None:
        totals["total_tokens"] += int(total_tokens)

    log_entry = {
        "timestamp": datetime.now(tz=timezone.utc).isoformat(),
        "provider": provider,
        "phase": phase,
        "label": label,
        "tokens_in": tokens_in,
        "tokens_out": tokens_out,
        "total_tokens": total_tokens,
        "metadata": metadata or {},
    }
    _write_log_entry(log_entry)


def summary() -> Dict[str, Dict[str, Dict[str, Dict[str, int]]]]:
    """Return nested dict provider -> phase -> label -> metrics."""
    report: Dict[str, Dict[str, Dict[str, Dict[str, int]]]] = {}
    for (provider, phase, label), count in _CALL_COUNTS.items():
        totals = _TOKEN_TOTALS.get((provider, phase, label), {})
        report.setdefault(provider, {}).setdefault(phase, {})[label] = {
            "count": count,
            "tokens_in": totals.get("tokens_in", 0),
            "tokens_out": totals.get("tokens_out", 0),
            "total_tokens": totals.get("total_tokens", 0),
        }
    return report


def summary_lines() -> Iterable[str]:
    """Return formatted strings summarizing counters and token usage."""
    if not _CALL_COUNTS:
        return ["No LLM calls recorded yet."]

    lines = ["LLM Call Summary:"]
    for provider, phase_map in summary().items():
        lines.append(f"- Provider: {provider}")
        for phase, label_map in phase_map.items():
            lines.append(f"  â€¢ Phase: {phase}")
            for label, stats in sorted(label_map.items()):
                count = stats["count"]
                tokens_in = stats["tokens_in"]
                tokens_out = stats["tokens_out"]
                total = stats["total_tokens"]
                lines.append(
                    f"    - {label}: {count} call(s), in={tokens_in}, out={tokens_out}, total={total}"
                )
    return lines


def reset() -> None:
    """Reset counters to zero (does not truncate log file)."""
    _CALL_COUNTS.clear()
    _TOKEN_TOTALS.clear()


def extract_token_usage(usage: object) -> Tuple[Optional[int], Optional[int], Optional[int]]:
    """
    Attempt to normalize token usage metadata returned by different providers.

    Args:
        usage: Provider-specific usage object or dict.

    Returns:
        Tuple of (tokens_in, tokens_out, total_tokens), each Optional[int].
    """
    if usage is None:
        return None, None, None

    tokens_in: Optional[int] = None
    tokens_out: Optional[int] = None
    total_tokens: Optional[int] = None

    # Dictionary-style usage payloads (e.g., Mistral)
    if isinstance(usage, dict):
        tokens_in = usage.get("prompt_tokens") or usage.get("input_tokens") or usage.get("prompt_token_count")
        tokens_out = usage.get("completion_tokens") or usage.get("output_tokens") or usage.get("candidates_token_count")
        total_tokens = usage.get("total_tokens") or usage.get("total_token_count")
    else:
        # Generic attribute access for objects (e.g., Gemini usage metadata)
        tokens_in = getattr(usage, "prompt_token_count", None)
        if tokens_in is None:
            tokens_in = getattr(usage, "prompt_tokens", None)
        if tokens_in is None:
            tokens_in = getattr(usage, "input_tokens", None)

        tokens_out = getattr(usage, "candidates_token_count", None)
        if tokens_out is None:
            tokens_out = getattr(usage, "completion_tokens", None)
        if tokens_out is None:
            tokens_out = getattr(usage, "output_tokens", None)

        total_tokens = getattr(usage, "total_token_count", None)
        if total_tokens is None:
            total_tokens = getattr(usage, "total_tokens", None)

    def _coerce(value: Optional[int]) -> Optional[int]:
        if value is None:
            return None
        try:
            return int(value)
        except (TypeError, ValueError):
            return None

    return _coerce(tokens_in), _coerce(tokens_out), _coerce(total_tokens)
